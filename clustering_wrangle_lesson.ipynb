{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualizing\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# default pandas decimal number display format\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google sheet: https://docs.google.com/spreadsheets/d/14L32EfCmr2asv85i08fla6jf1KakJVcLYaJMkXQ4_p0/edit#gid=0    \n",
    "\n",
    "#Note: Data has been filtered/changed a bit from orginal form to demonstrate null and outlier handling.\n",
    "\n",
    "\n",
    "sheet_url = 'https://docs.google.com/spreadsheets/d/14L32EfCmr2asv85i08fla6jf1KakJVcLYaJMkXQ4_p0/edit#gid=0'    \n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df = pd.read_csv(csv_export_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### How to handle nulls and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I handle missing data (nulls) in my dataset?\n",
    "\n",
    "- Drop the nulls\n",
    "    - drop columns\n",
    "    - drop rows\n",
    "- Impute missing values\n",
    "    - fillna with mean, median, mode of the column\n",
    "    - Impute using some other algorithms - KNN imputer\n",
    "- Use algorithms which can handle nulls\n",
    "    - Ignores missing values\n",
    "- Boolean flags for missing data \n",
    "    - (https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html#sklearn.impute.MissingIndicator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many nulls have in each column?\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % values missing in each column\n",
    "\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many nulls have in each row?\n",
    "\n",
    "df.isnull().sum(axis =1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop columns using dropna() based on a threshold\n",
    "\n",
    "# threshold: Require that many non-NA values to survive. \n",
    "\n",
    "df.dropna(axis = 1, thresh = 0.5 * len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows using dropna() based on a threshold\n",
    "\n",
    "# threshold: only drop when # of nulls in a row is above the threshold value\n",
    "\n",
    "df.dropna(axis = 0, thresh = 0.5 * len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_row = 0.5, prop_required_col = 0.5):\n",
    "    ''' function which takes in a dataframe, required notnull proportions of non-null rows and columns.\n",
    "    drop the columns and rows columns based on theshold:'''\n",
    "    \n",
    "    #drop columns with nulls\n",
    "    threshold = int(prop_required_col * len(df.index)) # Require that many non-NA values.\n",
    "    df.dropna(axis = 1, thresh = threshold, inplace = True)\n",
    "    \n",
    "    #drop rows with nulls\n",
    "    threshold = int(prop_required_row * len(df.columns)) # Require that many non-NA values.\n",
    "    df.dropna(axis = 0, thresh = threshold, inplace = True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function on our dataset\n",
    "df = handle_missing_values(df, prop_required_row = 0.5, prop_required_col = 0.5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null rows for specific columns only\n",
    "\n",
    "df = df[df.YearsCode.notnull()]\n",
    "df = df[df.YearsCodePro.notnull()]\n",
    "df = df[df.Age1stCode.notnull()]\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the most common/frequent observation in Gender in train dataset?\n",
    "df.Gender.value_counts()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs with mode\n",
    "\n",
    "df.Gender.mode()[0]\n",
    "\n",
    "df['Gender'] = df.Gender.fillna(df.Gender.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I simply convert the object columns to float/int using 'astype'?\n",
    "df['Age1stCode'] = df.Age1stCode.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have some strings these columns preventing them to be converted to int dtypes\n",
    "df.YearsCode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age1stCode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use replace function to reaplce strings with values\n",
    "\n",
    "df.replace('Younger than 5 years',4, inplace = True )\n",
    "df.replace('Older than 85', 85, inplace = True )\n",
    "\n",
    "df.replace('More than 50 years', 50, inplace = True )\n",
    "\n",
    "df.replace('Less than 1 year', 0, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can change datatype for these columns from 'object' to 'int64'\n",
    "\n",
    "df['Age1stCode'] = df.Age1stCode.astype('int64')\n",
    "df['YearsCode'] = df.YearsCode.astype('int64')\n",
    "df['YearsCodePro'] = df.YearsCodePro.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to impute age using other columns, but I need to split my data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in train, validate and test dataframes\n",
    "train, test = train_test_split(df,test_size=0.2, random_state=42)\n",
    "train, validate = train_test_split(train,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of three dataframes\n",
    "train.shape,validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use KNN imputer to find missing values for 'Age' \n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Use numeric columns that you want to use for imputation\n",
    "X_numeric = train[['Age', 'Age1stCode', 'YearsCode', 'YearsCodePro']]\n",
    "\n",
    "# define the thing\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "# fit the thing (or fit and use with fit_transform) only on train!\n",
    "train_imputed = imputer.fit_transform(X_numeric)\n",
    "train_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check there is no null in imputed columns\n",
    "pd.DataFrame(train_imputed).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert imputed array to a dataframe\n",
    "train_imputed = pd.DataFrame(train_imputed, index = train.index)\n",
    "train_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign imputed values to the age column\n",
    "train['Age'] = train_imputed[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the transformation on validate and test\n",
    "validate_imputed = imputer.transform(validate[['Age', 'Age1stCode', 'YearsCode', 'YearsCodePro']])\n",
    "test_imputed = imputer.transform(test[['Age', 'Age1stCode', 'YearsCode', 'YearsCodePro']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrarys from above cell in dataframes\n",
    "validate_imputed = pd.DataFrame(validate_imputed, index = validate.index)\n",
    "test_imputed = pd.DataFrame(test_imputed, index = test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign imputed to 'Age' column for validate and test dataframes\n",
    "validate['Age'] = validate_imputed[[0]]\n",
    "test['Age'] = test_imputed[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "- Data point(s) that differs significantly from other observations\n",
    "- Could be due to chance, measurement errors, transcription error, sampling error/bias,\n",
    "\n",
    "Question to ask:\n",
    "- Is the outlier part of population that I want to explore/model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms from Age and Compensation\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "df.Age.hist(bins = 100)\n",
    "plt.title('Age')\n",
    "\n",
    "plt.subplot(122)\n",
    "df.Comp.hist(bins = 100)\n",
    "plt.title('Compensation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for Age and Compensation\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.boxplot(y = 'Age', data = df, whis = 3)\n",
    "plt.title('Age')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Compensation')\n",
    "sns.boxplot(y = 'Comp', data = df, whis = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers:\n",
    "- Use domain knowledge/business rules to have cut-offs\n",
    "- Use IQR method to exclude outliers\n",
    "- Cap/Trim max value \n",
    "- transformation\n",
    "- Impute new value (if you know outlier is a mistake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate q1, q3 and iqr for Age\n",
    "\n",
    "q1 = df.Age.quantile(0.25)\n",
    "q3 = df.Age.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "k = 3\n",
    "\n",
    "# calculate upper and lower ranges\n",
    "upper_bound_Age =  q3 + k * iqr\n",
    "lower_bound_Age =  q1 - k * iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate q1, q3 and iqr for Comp\n",
    "\n",
    "\n",
    "q1 = df.Comp.quantile(0.25)\n",
    "q3 = df.Comp.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "k = 3\n",
    "\n",
    "# calculate upper and lower ranges\n",
    "upper_bound_Comp = q3 + k * iqr\n",
    "lower_bound_Comp = q1 - k * iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe using multiple conditions\n",
    "\n",
    "df[(df.Age < upper_bound_Age) & (df.Comp < upper_bound_Comp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap the limit\n",
    "\n",
    "# df['column'] = np.where(this_is_true(?), do_this, else_do_that)\n",
    "\n",
    "df.Comp_capped = np.where(df.Comp > 1_000_000, df.Comp == 1_000_000, df.Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
